{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習內容』\n",
    "#### 運用這幾天所學觀念搭建一個CNN分類器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 『本次練習目的』\n",
    "  #### 熟悉CNN分類器搭建步驟與原理\n",
    "  #### 學員們可以嘗試不同搭法，如使用不同的Maxpooling層，用GlobalAveragePooling取代Flatten等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n170500096/170498071 [==============================] - 24s 0us/step\n(50000, 32, 32, 3)\n"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print(x_train.shape) #(50000, 32, 32, 3)\n",
    "\n",
    "## Normalize Data\n",
    "def normalize(X_train,X_test):\n",
    "        mean = np.mean(X_train,axis=(0,1,2,3))\n",
    "        std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "        X_train = (X_train-mean)/(std+1e-7)\n",
    "        X_test = (X_test-mean)/(std+1e-7) \n",
    "        return X_train, X_test,mean,std\n",
    "    \n",
    "    \n",
    "## Normalize Training and Testset    \n",
    "x_train, x_test,mean_train,std_train = normalize(x_train, x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "C:\\Users\\asus\\.conda\\envs\\DL100\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\nIf you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\nIn case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n  warnings.warn(msg, FutureWarning)\n"
    }
   ],
   "source": [
    "## OneHot Label 由(None, 1)-(None, 10)\n",
    "## ex. label=2,變成[0,0,1,0,0,0,0,0,0,0]\n",
    "one_hot=OneHotEncoder()\n",
    "y_train=one_hot.fit_transform(y_train).toarray()\n",
    "y_test=one_hot.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_14 (Conv2D)           (None, 32, 32, 32)        896       \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 32, 32, 32)        128       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 16, 16, 32)        9248      \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 16, 16, 32)        128       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n_________________________________________________________________\nflatten_7 (Flatten)          (None, 2048)              0         \n_________________________________________________________________\ndense_10 (Dense)             (None, 100)               204900    \n_________________________________________________________________\ndense_11 (Dense)             (None, 10)                1010      \n=================================================================\nTotal params: 216,310\nTrainable params: 216,182\nNon-trainable params: 128\n_________________________________________________________________\nNone\nTrain on 50000 samples\nEpoch 1/100\n50000/50000 [==============================] - 16s 320us/sample - loss: 1.3793 - accuracy: 0.5142\nEpoch 2/100\n50000/50000 [==============================] - 15s 296us/sample - loss: 1.0145 - accuracy: 0.6452\nEpoch 3/100\n50000/50000 [==============================] - 16s 327us/sample - loss: 0.8810 - accuracy: 0.6929\nEpoch 4/100\n50000/50000 [==============================] - 21s 427us/sample - loss: 0.7950 - accuracy: 0.7256\nEpoch 5/100\n50000/50000 [==============================] - 16s 321us/sample - loss: 0.7148 - accuracy: 0.7509\nEpoch 6/100\n50000/50000 [==============================] - 16s 324us/sample - loss: 0.6455 - accuracy: 0.7742\nEpoch 7/100\n50000/50000 [==============================] - 17s 330us/sample - loss: 0.5810 - accuracy: 0.7971\nEpoch 8/100\n50000/50000 [==============================] - 16s 316us/sample - loss: 0.5174 - accuracy: 0.8211\nEpoch 9/100\n50000/50000 [==============================] - 14s 288us/sample - loss: 0.4616 - accuracy: 0.8395\nEpoch 10/100\n50000/50000 [==============================] - 21s 423us/sample - loss: 0.4039 - accuracy: 0.8593\nEpoch 11/100\n50000/50000 [==============================] - 14s 282us/sample - loss: 0.3513 - accuracy: 0.8788\nEpoch 12/100\n50000/50000 [==============================] - 15s 296us/sample - loss: 0.3034 - accuracy: 0.8951\nEpoch 13/100\n50000/50000 [==============================] - 17s 347us/sample - loss: 0.2634 - accuracy: 0.9103\nEpoch 14/100\n50000/50000 [==============================] - 16s 321us/sample - loss: 0.2130 - accuracy: 0.9288\nEpoch 15/100\n50000/50000 [==============================] - 15s 292us/sample - loss: 0.1881 - accuracy: 0.9365\nEpoch 16/100\n50000/50000 [==============================] - 15s 294us/sample - loss: 0.1625 - accuracy: 0.9459\nEpoch 17/100\n50000/50000 [==============================] - 16s 318us/sample - loss: 0.1388 - accuracy: 0.9531\nEpoch 18/100\n50000/50000 [==============================] - 16s 310us/sample - loss: 0.1192 - accuracy: 0.9611\nEpoch 19/100\n50000/50000 [==============================] - 15s 302us/sample - loss: 0.1096 - accuracy: 0.9641\nEpoch 20/100\n50000/50000 [==============================] - 14s 283us/sample - loss: 0.0998 - accuracy: 0.9662\nEpoch 21/100\n50000/50000 [==============================] - 17s 333us/sample - loss: 0.0866 - accuracy: 0.9713\nEpoch 22/100\n50000/50000 [==============================] - 16s 313us/sample - loss: 0.0887 - accuracy: 0.9709\nEpoch 23/100\n50000/50000 [==============================] - 16s 322us/sample - loss: 0.0888 - accuracy: 0.9700\nEpoch 24/100\n50000/50000 [==============================] - 14s 277us/sample - loss: 0.0656 - accuracy: 0.9790\nEpoch 25/100\n50000/50000 [==============================] - 16s 328us/sample - loss: 0.0608 - accuracy: 0.9799\nEpoch 26/100\n50000/50000 [==============================] - 17s 341us/sample - loss: 0.0776 - accuracy: 0.9733\nEpoch 27/100\n50000/50000 [==============================] - 15s 301us/sample - loss: 0.0662 - accuracy: 0.9774\nEpoch 28/100\n50000/50000 [==============================] - 16s 327us/sample - loss: 0.0502 - accuracy: 0.9841\nEpoch 29/100\n50000/50000 [==============================] - 16s 322us/sample - loss: 0.0666 - accuracy: 0.9766\nEpoch 30/100\n50000/50000 [==============================] - 19s 371us/sample - loss: 0.0491 - accuracy: 0.9835\nEpoch 31/100\n50000/50000 [==============================] - 17s 335us/sample - loss: 0.0414 - accuracy: 0.9866\nEpoch 32/100\n50000/50000 [==============================] - 15s 303us/sample - loss: 0.0608 - accuracy: 0.9787\nEpoch 33/100\n50000/50000 [==============================] - 19s 383us/sample - loss: 0.0571 - accuracy: 0.9809\nEpoch 34/100\n50000/50000 [==============================] - 18s 356us/sample - loss: 0.0427 - accuracy: 0.9859\nEpoch 35/100\n50000/50000 [==============================] - 15s 291us/sample - loss: 0.0387 - accuracy: 0.9876\nEpoch 36/100\n50000/50000 [==============================] - 14s 288us/sample - loss: 0.0553 - accuracy: 0.9813\nEpoch 37/100\n50000/50000 [==============================] - 15s 297us/sample - loss: 0.0540 - accuracy: 0.9815\nEpoch 38/100\n50000/50000 [==============================] - 15s 299us/sample - loss: 0.0431 - accuracy: 0.9854\nEpoch 39/100\n50000/50000 [==============================] - 19s 373us/sample - loss: 0.0301 - accuracy: 0.9898\nEpoch 40/100\n50000/50000 [==============================] - 15s 294us/sample - loss: 0.0457 - accuracy: 0.9848\nEpoch 41/100\n50000/50000 [==============================] - 15s 291us/sample - loss: 0.0556 - accuracy: 0.9814\nEpoch 42/100\n50000/50000 [==============================] - 16s 326us/sample - loss: 0.0316 - accuracy: 0.9891\nEpoch 43/100\n50000/50000 [==============================] - 15s 301us/sample - loss: 0.0253 - accuracy: 0.9917\nEpoch 44/100\n50000/50000 [==============================] - 16s 316us/sample - loss: 0.0503 - accuracy: 0.9827\nEpoch 45/100\n50000/50000 [==============================] - 15s 298us/sample - loss: 0.0399 - accuracy: 0.9862\nEpoch 46/100\n50000/50000 [==============================] - 16s 313us/sample - loss: 0.0282 - accuracy: 0.9903\nEpoch 47/100\n50000/50000 [==============================] - 17s 332us/sample - loss: 0.0287 - accuracy: 0.9899\nEpoch 48/100\n50000/50000 [==============================] - 15s 309us/sample - loss: 0.0514 - accuracy: 0.9828\nEpoch 49/100\n50000/50000 [==============================] - 15s 299us/sample - loss: 0.0394 - accuracy: 0.9863\nEpoch 50/100\n50000/50000 [==============================] - 17s 337us/sample - loss: 0.0280 - accuracy: 0.9902\nEpoch 51/100\n50000/50000 [==============================] - 18s 353us/sample - loss: 0.0247 - accuracy: 0.9916\nEpoch 52/100\n50000/50000 [==============================] - 14s 286us/sample - loss: 0.0271 - accuracy: 0.9909\nEpoch 53/100\n50000/50000 [==============================] - 14s 283us/sample - loss: 0.0470 - accuracy: 0.9835\nEpoch 54/100\n50000/50000 [==============================] - 15s 303us/sample - loss: 0.0338 - accuracy: 0.9884\nEpoch 55/100\n50000/50000 [==============================] - 20s 409us/sample - loss: 0.0239 - accuracy: 0.9919\nEpoch 56/100\n50000/50000 [==============================] - 17s 349us/sample - loss: 0.0246 - accuracy: 0.9917\nEpoch 57/100\n50000/50000 [==============================] - 16s 319us/sample - loss: 0.0424 - accuracy: 0.9861\nEpoch 58/100\n50000/50000 [==============================] - 14s 273us/sample - loss: 0.0350 - accuracy: 0.9877\nEpoch 59/100\n50000/50000 [==============================] - 14s 274us/sample - loss: 0.0234 - accuracy: 0.9921\nEpoch 60/100\n50000/50000 [==============================] - 14s 287us/sample - loss: 0.0246 - accuracy: 0.9920\nEpoch 61/100\n50000/50000 [==============================] - 14s 279us/sample - loss: 0.0332 - accuracy: 0.9891\nEpoch 62/100\n50000/50000 [==============================] - 14s 275us/sample - loss: 0.0313 - accuracy: 0.9896\nEpoch 63/100\n50000/50000 [==============================] - 14s 273us/sample - loss: 0.0263 - accuracy: 0.9910\nEpoch 64/100\n50000/50000 [==============================] - 14s 270us/sample - loss: 0.0272 - accuracy: 0.9906\nEpoch 65/100\n50000/50000 [==============================] - 13s 264us/sample - loss: 0.0249 - accuracy: 0.9921\nEpoch 66/100\n50000/50000 [==============================] - 13s 269us/sample - loss: 0.0193 - accuracy: 0.9932\nEpoch 67/100\n50000/50000 [==============================] - 14s 276us/sample - loss: 0.0321 - accuracy: 0.9893\nEpoch 68/100\n50000/50000 [==============================] - 13s 267us/sample - loss: 0.0291 - accuracy: 0.9904\nEpoch 69/100\n50000/50000 [==============================] - 13s 267us/sample - loss: 0.0286 - accuracy: 0.9908\nEpoch 70/100\n50000/50000 [==============================] - 14s 283us/sample - loss: 0.0181 - accuracy: 0.9939\nEpoch 71/100\n50000/50000 [==============================] - 14s 279us/sample - loss: 0.0207 - accuracy: 0.9931\nEpoch 72/100\n50000/50000 [==============================] - 14s 288us/sample - loss: 0.0373 - accuracy: 0.9878\nEpoch 73/100\n50000/50000 [==============================] - 14s 278us/sample - loss: 0.0249 - accuracy: 0.9917\nEpoch 74/100\n50000/50000 [==============================] - 14s 278us/sample - loss: 0.0194 - accuracy: 0.9934\nEpoch 75/100\n50000/50000 [==============================] - 14s 279us/sample - loss: 0.0186 - accuracy: 0.9937\nEpoch 76/100\n50000/50000 [==============================] - 15s 295us/sample - loss: 0.0286 - accuracy: 0.9902\nEpoch 77/100\n50000/50000 [==============================] - 18s 358us/sample - loss: 0.0246 - accuracy: 0.9918\nEpoch 78/100\n50000/50000 [==============================] - 17s 336us/sample - loss: 0.0208 - accuracy: 0.9927\nEpoch 79/100\n50000/50000 [==============================] - 17s 335us/sample - loss: 0.0260 - accuracy: 0.9911\nEpoch 80/100\n50000/50000 [==============================] - 16s 329us/sample - loss: 0.0224 - accuracy: 0.9925\nEpoch 81/100\n50000/50000 [==============================] - 16s 319us/sample - loss: 0.0168 - accuracy: 0.9940\nEpoch 82/100\n50000/50000 [==============================] - 13s 269us/sample - loss: 0.0218 - accuracy: 0.9929\nEpoch 83/100\n50000/50000 [==============================] - 13s 270us/sample - loss: 0.0302 - accuracy: 0.9898\nEpoch 84/100\n50000/50000 [==============================] - 13s 269us/sample - loss: 0.0224 - accuracy: 0.9927\nEpoch 85/100\n50000/50000 [==============================] - 13s 269us/sample - loss: 0.0236 - accuracy: 0.9917\nEpoch 86/100\n50000/50000 [==============================] - 13s 269us/sample - loss: 0.0245 - accuracy: 0.9918\nEpoch 87/100\n50000/50000 [==============================] - 13s 267us/sample - loss: 0.0137 - accuracy: 0.9952\nEpoch 88/100\n50000/50000 [==============================] - 13s 267us/sample - loss: 0.0114 - accuracy: 0.9963\nEpoch 89/100\n50000/50000 [==============================] - 13s 270us/sample - loss: 0.0207 - accuracy: 0.9930\nEpoch 90/100\n50000/50000 [==============================] - 13s 269us/sample - loss: 0.0334 - accuracy: 0.9894\nEpoch 91/100\n50000/50000 [==============================] - 14s 276us/sample - loss: 0.0184 - accuracy: 0.9935\nEpoch 92/100\n50000/50000 [==============================] - 13s 259us/sample - loss: 0.0146 - accuracy: 0.9951\nEpoch 93/100\n50000/50000 [==============================] - 14s 280us/sample - loss: 0.0227 - accuracy: 0.9922\nEpoch 94/100\n50000/50000 [==============================] - 14s 277us/sample - loss: 0.0233 - accuracy: 0.9924\nEpoch 95/100\n50000/50000 [==============================] - 13s 259us/sample - loss: 0.0214 - accuracy: 0.9934\nEpoch 96/100\n50000/50000 [==============================] - 13s 259us/sample - loss: 0.0165 - accuracy: 0.9946\nEpoch 97/100\n50000/50000 [==============================] - 13s 268us/sample - loss: 0.0137 - accuracy: 0.9955\nEpoch 98/100\n50000/50000 [==============================] - 14s 279us/sample - loss: 0.0200 - accuracy: 0.9934\nEpoch 99/100\n50000/50000 [==============================] - 14s 277us/sample - loss: 0.0194 - accuracy: 0.9939\nEpoch 100/100\n50000/50000 [==============================] - 13s 261us/sample - loss: 0.0195 - accuracy: 0.9937\n"
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2a9a54a6898>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "classifier=Sequential()\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same',input_shape = (32,32,3)))#32,3,3,input_shape=(32,32,3),activation='relu''\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "'''自己決定MaxPooling2D放在哪裡'''\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "#卷積組合\n",
    "classifier.add(Convolution2D(32, kernel_size=(3, 3), padding='same'))\n",
    "classifier.add(BatchNormalization())\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#flatten\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#FC\n",
    "classifier.add(Dense(100,activation='relu')) #output_dim=100,activation=relu\n",
    "\n",
    "#輸出\n",
    "classifier.add(Dense(10,activation='softmax'))\n",
    "print(classifier.summary())\n",
    "#超過兩個就要選categorical_crossentrophy\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(x_train,y_train,batch_size=100,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 預測新圖片，輸入影像前處理要與訓練時相同\n",
    "#### ((X-mean)/(std+1e-7) ):這裡的mean跟std是訓練集的\n",
    "## 維度如下方示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.4842011e-10, 1.4329931e-19, 4.3974919e-12, 9.6832734e-01,\n        3.1672716e-02, 2.2994348e-16, 5.1054144e-12, 2.7864542e-12,\n        5.1747193e-11, 2.8436167e-17]], dtype=float32)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example=(np.zeros(shape=(1,32,32,3))-mean_train)/(std_train+1e-7) \n",
    "classifier.predict(input_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}